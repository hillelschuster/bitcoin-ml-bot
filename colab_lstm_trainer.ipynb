{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin Trading Bot LSTM Model Trainer\n",
    "\n",
    "This notebook trains an LSTM model for the Bitcoin ML Trading Bot using Google Colab's GPU acceleration.\n",
    "\n",
    "## Workflow:\n",
    "1. Upload your `trades.db` file from your local bot\n",
    "2. Configure training parameters\n",
    "3. Train the LSTM model using GPU acceleration\n",
    "4. Download the trained model and scaler files\n",
    "5. Place the downloaded files in your local `model_artifacts/` directory\n",
    "\n",
    "## Requirements:\n",
    "- TensorFlow 2.x\n",
    "- Pandas\n",
    "- NumPy\n",
    "- Scikit-learn\n",
    "- SQLite3\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check GPU Availability\n",
    "\n",
    "First, let's verify that we have GPU acceleration available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Check for GPU\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# If GPU is available, set memory growth to avoid OOM errors\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth set to True for all GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error setting memory growth:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Trades Database\n",
    "\n",
    "Upload your `trades.db` file from your local bot's `logs/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Upload trades.db file\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the filename of the uploaded file\n",
    "db_filename = list(uploaded.keys())[0]\n",
    "print(f\"Uploaded: {db_filename}\")\n",
    "\n",
    "# If the uploaded file is not named trades.db, rename it\n",
    "if db_filename != \"trades.db\":\n",
    "    os.rename(db_filename, \"trades.db\")\n",
    "    db_filename = \"trades.db\"\n",
    "    print(f\"Renamed to: {db_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Data\n",
    "\n",
    "Now let's load the trade data from the database and prepare it for LSTM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = sqlite3.connect(db_filename)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Check if the trades table exists\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='trades'\")\n",
    "if not cursor.fetchone():\n",
    "    print(\"Error: 'trades' table not found in the database.\")\n",
    "else:\n",
    "    # Get column names\n",
    "    cursor.execute(\"PRAGMA table_info(trades)\")\n",
    "    columns = [col[1] for col in cursor.fetchall()]\n",
    "    print(f\"Columns in trades table: {columns}\")\n",
    "    \n",
    "    # Query all trades\n",
    "    cursor.execute(\"SELECT * FROM trades ORDER BY timestamp\")\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    print(f\"Loaded {len(df)} trades from database\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have enough real trades for training\n",
    "if len(df) < 100:\n",
    "    print(\"❌ Not enough real trades for LSTM training.\")\n",
    "    print(\"✅ Please upload a valid trades.db file with at least 100 entries in the 'trades' table.\")\n",
    "    raise ValueError(\"Aborting training: insufficient real trade data.\")\n",
    "else:\n",
    "    print(f\"✅ Loaded {len(df)} real trades. Proceeding with training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LSTM\n",
    "def prepare_sequences(df, sequence_length=10):\n",
    "    \"\"\"Prepare sequences for LSTM training.\"\"\"\n",
    "    # Ensure price column is numeric\n",
    "    if 'price' in df.columns:\n",
    "        df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "    else:\n",
    "        # If price column doesn't exist, try to use entry_price or exit_price\n",
    "        if 'entry_price' in df.columns:\n",
    "            df['price'] = pd.to_numeric(df['entry_price'], errors='coerce')\n",
    "        elif 'exit_price' in df.columns:\n",
    "            df['price'] = pd.to_numeric(df['exit_price'], errors='coerce')\n",
    "        else:\n",
    "            raise ValueError(\"No price column found in the data\")\n",
    "    \n",
    "    # Drop rows with NaN prices\n",
    "    df = df.dropna(subset=['price'])\n",
    "    \n",
    "    # Sort by timestamp if available\n",
    "    if 'timestamp' in df.columns:\n",
    "        df = df.sort_values('timestamp')\n",
    "    \n",
    "    # Extract price series\n",
    "    prices = df['price'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Scale the prices\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    prices_scaled = scaler.fit_transform(prices)\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(prices_scaled) - sequence_length):\n",
    "        X.append(prices_scaled[i:i+sequence_length])\n",
    "        \n",
    "        # For the target, we'll predict the direction (1 for up, 0 for down or same)\n",
    "        next_price = prices_scaled[i+sequence_length][0]\n",
    "        current_price = prices_scaled[i+sequence_length-1][0]\n",
    "        y.append(1 if next_price > current_price else 0)\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler\n",
    "\n",
    "# Prepare sequences\n",
    "sequence_length = 10  # Number of previous prices to use for prediction\n",
    "X, y, scaler = prepare_sequences(df, sequence_length)\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build and Train LSTM Model\n",
    "\n",
    "Now let's build and train the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "def build_lstm_model(sequence_length, features=1):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(sequence_length, features)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_lstm_model(sequence_length)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Create directory for model checkpoints\n",
    "os.makedirs('model_checkpoints', exist_ok=True)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'model_checkpoints/lstm_model_checkpoint.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on validation set\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation Loss: {loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Model and Scaler\n",
    "\n",
    "Now let's save the trained model and scaler for use in the trading bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('lstm_model.h5')\n",
    "print(\"Model saved to lstm_model.h5\")\n",
    "\n",
    "# Save scaler\n",
    "with open('lstm_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"Scaler saved to lstm_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Model Prediction\n",
    "\n",
    "Let's test the model with a sample sequence to ensure it works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample sequence from the validation set\n",
    "sample_sequence = X_val[0]\n",
    "true_label = y_val[0]\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(sample_sequence.reshape(1, sequence_length, 1))[0][0]\n",
    "predicted_label = 1 if prediction > 0.5 else 0\n",
    "\n",
    "print(f\"Prediction probability: {prediction:.4f}\")\n",
    "print(f\"Predicted label: {predicted_label} ({'UP' if predicted_label == 1 else 'DOWN'})\")\n",
    "print(f\"True label: {true_label} ({'UP' if true_label == 1 else 'DOWN'})\")\n",
    "\n",
    "# Decode the sequence to show actual prices\n",
    "original_prices = scaler.inverse_transform(sample_sequence)\n",
    "print(\"\\nSequence prices:\")\n",
    "for i, price in enumerate(original_prices):\n",
    "    print(f\"  t-{sequence_length-i}: ${price[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Download Model Files\n",
    "\n",
    "Finally, let's download the trained model and scaler files for use in the trading bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download model and scaler files\n",
    "files.download('lstm_model.h5')\n",
    "files.download('lstm_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Instructions for Using the Model\n",
    "\n",
    "1. Download both `lstm_model.h5` and `lstm_scaler.pkl` files\n",
    "2. Place them in your local bot's `model_artifacts/` directory\n",
    "3. Run your trading bot - it should now pass the model verification check\n",
    "\n",
    "The model is trained to predict price direction (UP or DOWN) based on the previous 10 price points. The prediction is a probability between 0 and 1, where values above 0.5 indicate an upward prediction and values below 0.5 indicate a downward prediction.\n",
    "\n",
    "You can retrain this model periodically as more trade data becomes available."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
